{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['trX', 'trY', 'tstX', 'tstY']>\n"
     ]
    }
   ],
   "source": [
    "# Load and open the file containing the data\n",
    "myFile = h5py.File('data-Mini Project 2.h5', 'r+')\n",
    "\n",
    "# List all groups in the .h5 file\n",
    "print(f\"Keys: {myFile.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"trX\": shape (3000, 150, 3), type \"<f8\">\n",
      "<HDF5 dataset \"trY\": shape (3000, 6), type \"<f8\">\n",
      "<HDF5 dataset \"tstX\": shape (600, 150, 3), type \"<f8\">\n",
      "<HDF5 dataset \"tstY\": shape (600, 6), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "# print the information about the keys in the data\n",
    "for key in myFile.keys():\n",
    "    print(myFile[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trX shape: (3000, 150, 3), dtype: float64\n",
      "trY shape: (3000, 6), dtype: float64\n",
      "tstX shape: (600, 150, 3), dtype: float64\n",
      "tstY shape: (600, 6), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Extract the data from the file as numpy arrays\n",
    "\n",
    "n1 = myFile.get('trX')  # trX is the training data\n",
    "trX = np.array(n1)\n",
    "print(f\"trX shape: {trX.shape}, dtype: {trX.dtype}\")\n",
    "\n",
    "n1 = myFile.get('trY')  # trY is the training labels\n",
    "trY = np.array(n1)\n",
    "print(f\"trY shape: {trY.shape}, dtype: {trY.dtype}\")\n",
    "\n",
    "n1 = myFile.get('tstX') # tstX is the test data\n",
    "tstX = np.array(n1)\n",
    "print(f\"tstX shape: {tstX.shape}, dtype: {tstX.dtype}\")\n",
    "\n",
    "n1 = myFile.get('tstY') # tstY is the test labels\n",
    "tstY = np.array(n1)\n",
    "print(f\"tstY shape: {tstY.shape}, dtype: {tstY.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trX shape: (3000, 150, 3), dtype: float64\n",
      "trY shape: (3000, 6), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# close the .h5 file\n",
    "myFile.close()\n",
    "\n",
    "# shuffle the training and the test data\n",
    "indexes = np.arange(trX.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "trX = trX[indexes]\n",
    "trY = trY[indexes]\n",
    "\n",
    "indexes = np.arange(tstX.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "tstX = tstX[indexes]\n",
    "tstY = tstY[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tanh activation function for the hidden layer\n",
    "def tanh_activation(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "# tanh derivative\n",
    "def tanh_derivative(x):\n",
    "    return 1.0 - np.tanh(x) ** 2\n",
    "\n",
    "# sigmoid activation function for the output layer\n",
    "def sigmoid_activation(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# sigmoid derivative\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, trX, trY, tstX, tstY, N, learning_rate, mini_batch_size, num_epochs):\n",
    "        # initialize the data\n",
    "        self.trX = trX  # 3000 x 150 x 3\n",
    "        self.trY = trY  # 3000 x 6\n",
    "        self.tstX = tstX    # 600 x 150 x 3\n",
    "        self.tstY = tstY    # 600 x 6\n",
    "        \n",
    "        # add the bias to the data\n",
    "        self.trX = np.concatenate((self.trX, np.ones((self.trX.shape[0], self.trX.shape[1], 1))), axis=2)   # 3000 x 150 x 4\n",
    "        self.tstX = np.concatenate((self.tstX, np.ones((self.tstX.shape[0], self.tstX.shape[1], 1))), axis=2)   # 600 x 150 x 4\n",
    "\n",
    "        # initialize the hyperparameters\n",
    "        self.N = N\n",
    "        self.learning_rate = learning_rate\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "        # initialize the weights and biases\n",
    "        self.Whh = np.random.uniform(-0.1, 0.1, (self.N, self.N))   # N x N\n",
    "        self.W1h = np.random.uniform(-0.1, 0.1, (self.N, 3+1))  # N x 4\n",
    "        self.Who = np.random.uniform(-0.1, 0.1, (6, self.N+1))  # 6 x (N+1)\n",
    "\n",
    "    # forward pass\n",
    "    def forward_pass(self, x):\n",
    "        # x is a 150x4 vector where the first 3 elements are the sensor data and the last element is the bias with 150 time steps\n",
    "        # initialize hidden layer\n",
    "        h = np.zeros((self.N, 1))   # N x 1\n",
    "        # initialize hidden layer output\n",
    "        h_out = np.zeros((self.N, 1))   # N x 1\n",
    "        # initialize output layer\n",
    "        y = np.zeros((6, 1))\n",
    "        # initialize hidden states\n",
    "        hidden_states = []\n",
    "        hidden_states.append(np.zeros((self.N, 1))) # initial state\n",
    "        \n",
    "        # initialize the predictions\n",
    "        preds = []\n",
    "\n",
    "        # loop over the time steps\n",
    "        for t in range(x.shape[0]):\n",
    "            # update the hidden layer\n",
    "            h = np.matmul(self.Whh, h) + np.matmul(self.W1h, x[t].reshape(-1, 1))\n",
    "            # update the hidden layer output\n",
    "            h_out = tanh_activation(h)\n",
    "            hidden_states.append(h_out)\n",
    "            # add the bias to the hidden layer output\n",
    "            h_out = np.concatenate((h_out, np.ones((1, 1))), axis=0)\n",
    "            # update the output layer\n",
    "            y = np.matmul(self.Who, h_out)\n",
    "            # apply the sigmoid activation function to the output layer\n",
    "            y = sigmoid_activation(y)\n",
    "            preds.append(y)\n",
    "\n",
    "        return y, hidden_states\n",
    "    \n",
    "    # multi category cross entropy loss function\n",
    "    def loss_function(self, y, pred):\n",
    "        loss = np.sum(y * np.log(pred) + (1 - y) * np.log(1 - pred))\n",
    "        return -loss\n",
    "\n",
    "    # backpropagation\n",
    "    def backpropagation(self, x, y, pred, hidden_states, batch_size):\n",
    "        # divide the data into mini batches\n",
    "        x = np.array_split(x, batch_size)\n",
    "        y = np.array_split(y, batch_size)\n",
    "        pred = np.array_split(pred, batch_size)\n",
    "\n",
    "        for i in range(0, x.shape[0], batch_size):\n",
    "            # initialize the gradients\n",
    "            dW1h = np.zeros_like(self.W1h)\n",
    "            dWhh = np.zeros_like(self.Whh)\n",
    "            dWho = np.zeros_like(self.Who)\n",
    "            \n",
    "            dH = np.zeros_like(hidden_states[0])\n",
    "            \n",
    "            err = pred - y\n",
    "            \n",
    "            for t in reversed(range(x.shape[0])):\n",
    "                dWho += np.matmul(err, np.transpose(np.concatenate((hidden_states[t], np.ones((1, 1))), axis=0)))\n",
    "                dW1h += np.matmul(np.transpose(np.matmul(np.transpose(self.Who), err) * sigmoid_derivative(pred))), np.transpose(x[t].reshape(-1, 1))\n",
    "                dWhh += np.matmul(np.transpose(np.matmul(np.transpose(self.Who), err) * sigmoid_derivative(pred))), np.transpose(hidden_states[t])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # initialize the gradients\n",
    "        dW1h = np.zeros_like(self.W1h)\n",
    "        dWhh = np.zeros_like(self.Whh)\n",
    "        dWho = np.zeros_like(self.Who)\n",
    "        \n",
    "        dH = np.zeros_like(hidden_states[0])\n",
    "        \n",
    "        err = pred - y\n",
    "         \n",
    "        for t in reversed(range(x.shape[0])):\n",
    "            dWho += np.matmul(err, np.transpose(np.concatenate((hidden_states[t], np.ones((1, 1))), axis=0)))\n",
    "            dW1h += np.matmul(np.transpose(np.matmul(np.transpose(self.Who), err) * sigmoid_derivative(pred))), np.transpose(x[t].reshape(-1, 1))\n",
    "            dWhh += np.matmul(np.transpose(np.matmul(np.transpose(self.Who), err) * sigmoid_derivative(pred))), np.transpose(hidden_states[t])\n",
    "\n",
    "            \n",
    "        return dW1h, dWhh, dWho\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.51430912]\n",
      " [-0.48401401]\n",
      " [-0.51606605]\n",
      " [-0.47999247]\n",
      " [-0.50616072]\n",
      " [-0.47854115]]\n",
      "(6, 1)\n"
     ]
    }
   ],
   "source": [
    "print(rnn.trY[453].reshape(-1,1) - y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: [[0.48569088]\n",
      " [0.48401401]\n",
      " [0.51606605]\n",
      " [0.47999247]\n",
      " [0.50616072]\n",
      " [0.47854115]], shape: (6, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (51,1) (6,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\NSagi\\Music\\Desktop\\2023-24_Fall\\EEE-443\\Mini-Project_2\\Human-Activity-Recognition-Classification\\deneme.ipynb Cell 10\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m pred, hidden_states \u001b[39m=\u001b[39m rnn\u001b[39m.\u001b[39mforward_pass(rnn\u001b[39m.\u001b[39mtrX[\u001b[39m453\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my: \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m}\u001b[39;00m\u001b[39m, shape: \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m dW1h, dWhh, dWho \u001b[39m=\u001b[39m rnn\u001b[39m.\u001b[39;49mbackpropagation(rnn\u001b[39m.\u001b[39;49mtrX[\u001b[39m453\u001b[39;49m], rnn\u001b[39m.\u001b[39;49mtrY[\u001b[39m453\u001b[39;49m]\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m), pred, hidden_states)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdW1h shape: \u001b[39m\u001b[39m{\u001b[39;00mdW1h\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdWhh shape: \u001b[39m\u001b[39m{\u001b[39;00mdWhh\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\NSagi\\Music\\Desktop\\2023-24_Fall\\EEE-443\\Mini-Project_2\\Human-Activity-Recognition-Classification\\deneme.ipynb Cell 10\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X13sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mrange\u001b[39m(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X13sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     dWho \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearning_rate \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mmatmul((pred \u001b[39m-\u001b[39m y), np\u001b[39m.\u001b[39mtranspose(np\u001b[39m.\u001b[39mconcatenate((hidden_states[t], np\u001b[39m.\u001b[39mones((\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X13sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     dW1h \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearning_rate \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mmatmul(np\u001b[39m.\u001b[39mtranspose(np\u001b[39m.\u001b[39;49mmatmul(np\u001b[39m.\u001b[39;49mtranspose(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mWho), (pred \u001b[39m-\u001b[39;49m y)) \u001b[39m*\u001b[39;49m sigmoid_derivative(pred))), np\u001b[39m.\u001b[39mtranspose(x[t]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X13sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m     dWhh \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearning_rate \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mmatmul(np\u001b[39m.\u001b[39mtranspose(np\u001b[39m.\u001b[39mmatmul(np\u001b[39m.\u001b[39mtranspose(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mWho), (pred \u001b[39m-\u001b[39m y)) \u001b[39m*\u001b[39m sigmoid_derivative(pred))), np\u001b[39m.\u001b[39mtranspose(hidden_states[t])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X13sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39mreturn\u001b[39;00m dW1h, dWhh, dWho\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (51,1) (6,1) "
     ]
    }
   ],
   "source": [
    "# initialize the network\n",
    "N = 50\n",
    "learning_rate = 0.05\n",
    "mini_batch_size = 30\n",
    "num_epochs = 50\n",
    "rnn = RNN(trX, trY, tstX, tstY, N, learning_rate, mini_batch_size, num_epochs)\n",
    "pred, hidden_states = rnn.forward_pass(rnn.trX[453])\n",
    "print(f\"y: {y}, shape: {y.shape}\")\n",
    "dW1h, dWhh, dWho = rnn.backpropagation(rnn.trX[453], rnn.trY[453].reshape(-1, 1), pred, hidden_states)\n",
    "print(f\"dW1h shape: {dW1h.shape}\")\n",
    "print(f\"dWhh shape: {dWhh.shape}\")\n",
    "print(f\"dWho shape: {dWho.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sddsd: [[ 0.02326866]\n",
      " [ 0.00384134]\n",
      " [-0.18629913]\n",
      " [ 0.05566894]\n",
      " [-0.1628338 ]\n",
      " [-0.09714913]\n",
      " [ 0.09012098]\n",
      " [ 0.04816209]\n",
      " [ 0.11316556]\n",
      " [ 0.1126785 ]\n",
      " [ 0.05520445]\n",
      " [-0.01201024]\n",
      " [ 0.02801943]\n",
      " [-0.02045145]\n",
      " [-0.03128348]\n",
      " [ 0.09867042]\n",
      " [ 0.02498328]\n",
      " [-0.24751347]\n",
      " [ 0.0124767 ]\n",
      " [ 0.00815191]\n",
      " [ 0.08548786]\n",
      " [-0.10555946]\n",
      " [-0.18262522]\n",
      " [-0.00644319]\n",
      " [-0.0428866 ]\n",
      " [ 0.0815097 ]\n",
      " [-0.2047452 ]\n",
      " [ 0.02128189]\n",
      " [ 0.07166018]\n",
      " [ 0.06903144]\n",
      " [ 0.02238825]\n",
      " [-0.09805824]\n",
      " [ 0.05349618]\n",
      " [ 0.04149045]\n",
      " [-0.07361007]\n",
      " [ 0.08843927]\n",
      " [-0.02802942]\n",
      " [-0.0581105 ]\n",
      " [-0.05802994]\n",
      " [ 0.01777098]\n",
      " [ 0.06871799]\n",
      " [-0.1156942 ]\n",
      " [ 0.00690742]\n",
      " [ 0.06683557]\n",
      " [ 0.05482055]\n",
      " [-0.00556718]\n",
      " [ 0.04620477]\n",
      " [ 0.07555757]\n",
      " [-0.01169871]\n",
      " [ 0.01891714]\n",
      " [ 1.        ]], shape: (51, 1)\n"
     ]
    }
   ],
   "source": [
    "sddsd = np.concatenate((hidden_states[149], np.ones((1, 1))), axis=0)\n",
    "print(f\"sddsd: {sddsd}, shape: {sddsd.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (50,4) and (150,1) not aligned: 4 (dim 1) != 150 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\NSagi\\Music\\Desktop\\2023-24_Fall\\EEE-443\\Mini-Project_2\\Human-Activity-Recognition-Classification\\deneme.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# loop over the training examples\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(trX\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m# forward pass\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     y_hat \u001b[39m=\u001b[39m rnn\u001b[39m.\u001b[39;49mforward_pass(trX[i, :, :])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m# backward pass\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     rnn\u001b[39m.\u001b[39mbackward_pass(trX[i, :, :], trY[i, :, :], y_hat)\n",
      "\u001b[1;32mc:\\Users\\NSagi\\Music\\Desktop\\2023-24_Fall\\EEE-443\\Mini-Project_2\\Human-Activity-Recognition-Classification\\deneme.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# loop over the time steps\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m# update the hidden layer\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     h \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mWhh, h) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW1h, x[:, t]\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39m# update the hidden layer output\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     h_out \u001b[39m=\u001b[39m tanh_activation(h)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (50,4) and (150,1) not aligned: 4 (dim 1) != 150 (dim 0)"
     ]
    }
   ],
   "source": [
    "# implement the training loop and test the network on the test data\n",
    "# initialize the training loss\n",
    "tr_loss = np.zeros((num_epochs, 1))\n",
    "# initialize the test loss\n",
    "tst_loss = np.zeros((num_epochs, 1))\n",
    "\n",
    "# initialize the network\n",
    "N = 50\n",
    "learning_rate = 0.05\n",
    "mini_batch_size = 30\n",
    "num_epochs = 50\n",
    "rnn = RNN(trX, trY, tstX, tstY, N, learning_rate, mini_batch_size, num_epochs)\n",
    "\n",
    "# loop over the epochs\n",
    "for epoch in range(num_epochs):\n",
    "    # initialize the training loss for this epoch\n",
    "    tr_loss_epoch = 0\n",
    "    # initialize the test loss for this epoch\n",
    "    tst_loss_epoch = 0\n",
    "\n",
    "    # loop over the training examples\n",
    "    for i in range(trX.shape[0]):\n",
    "        # forward pass\n",
    "        y_hat = rnn.forward_pass(trX[i, :, :])\n",
    "        # backward pass\n",
    "        rnn.backward_pass(trX[i, :, :], trY[i, :, :], y_hat)\n",
    "        # update the weights and biases\n",
    "        Who = Who - learning_rate * rnn.delta_o * rnn.h.T\n",
    "        W1h = W1h - learning_rate * rnn.delta_h * rnn.h_out.T\n",
    "        Whh = Whh - learning_rate * rnn.delta_h * rnn.h.T\n",
    "\n",
    "        # calculate the training loss for this example\n",
    "        tr_loss_epoch = tr_loss_epoch + np.sum(np.square(trY[i, :, :] - y_hat))\n",
    "        # calculate the test loss for this example\n",
    "        tst_loss_epoch = tst_loss_epoch + np.sum(np.square(tstY[i, :, :] - y_hat))\n",
    "\n",
    "    # calculate the average training loss for this epoch\n",
    "    tr_loss[epoch] = tr_loss_epoch / trX.shape[0]\n",
    "    # calculate the average test loss for this epoch\n",
    "    tst_loss[epoch] = tst_loss_epoch / tstX.shape[0]\n",
    "\n",
    "    # print the training and test loss for this epoch\n",
    "    print(f\"Epoch: {epoch}, Training Loss: {tr_loss[epoch]}, Test Loss: {tst_loss[epoch]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "    def backward_pass(self, x, y, pred):\n",
    "        # initialize the error in the output layer\n",
    "        delta_o = np.zeros((6, 1))\n",
    "        # initialize the error in the hidden layer\n",
    "        delta_h = np.zeros((self.N, 1))\n",
    "\n",
    "        # loop over the time steps\n",
    "        for t in reversed(range(x.shape[1])):\n",
    "            # calculate the error in the output layer\n",
    "            delta_o = (pred[:, t].reshape(-1, 1) - y[:, t].reshape(-1, 1)) * pred[:, t].reshape(-1, 1) * (1 - pred[:, t].reshape(-1, 1))\n",
    "            # calculate the error in the hidden layer\n",
    "            delta_h = np.dot(self.Who.T) * delta_o + np.dot(self.Whh.T, delta_h)\n",
    "\n",
    "# Backpropagation Through Time (BPTT) function\n",
    "def bptt(trX, trY, W1h, Whh, Who, learning_rate, N):\n",
    "    hidden_states, outputs = forward_pass(trX, W1h, Whh, Who, N)\n",
    "    training_loss = cross_entropy_loss(outputs, trY)  # Compute training loss\n",
    "    dL_doutputs = outputs - trY\n",
    "\n",
    "    dW1h = np.zeros_like(W1h)\n",
    "    dWhh = np.zeros_like(Whh)\n",
    "    dWho = np.zeros_like(Who)\n",
    "\n",
    "    for t in reversed(range(trX.shape[1])):\n",
    "        dWho += np.dot(dL_doutputs.T, hidden_states)\n",
    "        dhidden = np.dot(dL_doutputs, Who) * dtanh(hidden_states)  # dtanh for derivative of tanh\n",
    "\n",
    "        for bptt_step in reversed(range(max(0, t - backprop_truncate), t+1)):\n",
    "            dWhh += np.dot(dhidden.T, hidden_states)\n",
    "            Xt_bias = np.hstack((trX[:, bptt_step, :], np.ones((trX.shape[0], 1))))\n",
    "            dW1h += np.dot(dhidden.T, Xt_bias)\n",
    "            dhidden = np.dot(dhidden, Whh) * dtanh(hidden_states)  # dtanh for derivative of tanh\n",
    "\n",
    "    W1h -= learning_rate * dW1h\n",
    "    Whh -= learning_rate * dWhh\n",
    "    Who -= learning_rate * dWho\n",
    "\n",
    "    return W1h, Whh, Who, training_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
