{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['trX', 'trY', 'tstX', 'tstY']>\n"
     ]
    }
   ],
   "source": [
    "# Load and open the file containing the data\n",
    "myFile = h5py.File('data-Mini Project 2.h5', 'r+')\n",
    "\n",
    "# List all groups in the .h5 file\n",
    "print(f\"Keys: {myFile.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"trX\": shape (3000, 150, 3), type \"<f8\">\n",
      "<HDF5 dataset \"trY\": shape (3000, 6), type \"<f8\">\n",
      "<HDF5 dataset \"tstX\": shape (600, 150, 3), type \"<f8\">\n",
      "<HDF5 dataset \"tstY\": shape (600, 6), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "# print the information about the keys in the data\n",
    "for key in myFile.keys():\n",
    "    print(myFile[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trX shape: (3000, 150, 3), dtype: float64\n",
      "trY shape: (3000, 6), dtype: float64\n",
      "tstX shape: (600, 150, 3), dtype: float64\n",
      "tstY shape: (600, 6), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Extract the data from the file as numpy arrays\n",
    "\n",
    "n1 = myFile.get('trX')  # trX is the training data\n",
    "trX = np.array(n1)\n",
    "print(f\"trX shape: {trX.shape}, dtype: {trX.dtype}\")\n",
    "\n",
    "n1 = myFile.get('trY')  # trY is the training labels\n",
    "trY = np.array(n1)\n",
    "print(f\"trY shape: {trY.shape}, dtype: {trY.dtype}\")\n",
    "\n",
    "n1 = myFile.get('tstX') # tstX is the test data\n",
    "tstX = np.array(n1)\n",
    "print(f\"tstX shape: {tstX.shape}, dtype: {tstX.dtype}\")\n",
    "\n",
    "n1 = myFile.get('tstY') # tstY is the test labels\n",
    "tstY = np.array(n1)\n",
    "print(f\"tstY shape: {tstY.shape}, dtype: {tstY.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the .h5 file\n",
    "myFile.close()\n",
    "\n",
    "# shuffle the training and the test data\n",
    "indexes = np.arange(trX.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "trX = trX[indexes]\n",
    "trY = trY[indexes]\n",
    "\n",
    "indexes = np.arange(tstX.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "tstX = tstX[indexes]\n",
    "tstY = tstY[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tanh activation function for the hidden layer\n",
    "def tanh_activation(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "# tanh derivative\n",
    "def tanh_derivative(x):\n",
    "    return 1.0 - np.tanh(x) ** 2\n",
    "\n",
    "# sigmoid activation function for the output layer\n",
    "def sigmoid_activation(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# sigmoid derivative\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, trX, trY, tstX, tstY, N, learning_rate, mini_batch_size, num_epochs):\n",
    "        # initialize the data\n",
    "        self.trX = trX  # 3000 x 150 x 3\n",
    "        self.trY = trY  # 3000 x 6\n",
    "        self.tstX = tstX    # 600 x 150 x 3\n",
    "        self.tstY = tstY    # 600 x 6\n",
    "        \n",
    "        # add the bias to the data\n",
    "        self.trX = np.concatenate((self.trX, np.ones((self.trX.shape[0], self.trX.shape[1], 1))), axis=2)   # 3000 x 150 x 4\n",
    "        self.tstX = np.concatenate((self.tstX, np.ones((self.tstX.shape[0], self.tstX.shape[1], 1))), axis=2)   # 600 x 150 x 4\n",
    "\n",
    "        # initialize the hyperparameters\n",
    "        self.N = N\n",
    "        self.learning_rate = learning_rate\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "        # initialize the weights and biases\n",
    "        self.Whh = np.random.uniform(-0.1, 0.1, (self.N, self.N))   # N x N\n",
    "        self.W1h = np.random.uniform(-0.1, 0.1, (self.N, 3+1))  # N x 4\n",
    "        self.Who = np.random.uniform(-0.1, 0.1, (6, self.N+1))  # 6 x (N+1)\n",
    "\n",
    "    # forward pass\n",
    "    def forward_pass(self, x):\n",
    "        # x is a 150x4 vector where the first 3 elements are the sensor data and the last element is the bias with 150 time steps\n",
    "        # initialize hidden layer\n",
    "        h = np.zeros((self.N, 1))   # N x 1\n",
    "        # initialize hidden layer output\n",
    "        h_out = np.zeros((self.N, 1))   # N x 1\n",
    "        # initialize output layer\n",
    "        y = np.zeros((6, 1))\n",
    "        # initialize hidden states\n",
    "        hidden_states = []\n",
    "        hidden_states.append(np.zeros((self.N, 1))) # initial state\n",
    "        \n",
    "        # initialize the predictions\n",
    "        preds = []\n",
    "\n",
    "        # loop over the time steps\n",
    "        for t in range(x.shape[0]):\n",
    "            # update the hidden layer\n",
    "            h = np.matmul(self.Whh, h) + np.matmul(self.W1h, x[t].reshape(-1, 1))\n",
    "            # update the hidden layer output\n",
    "            h_out = tanh_activation(h)\n",
    "            hidden_states.append(h_out)\n",
    "            # add the bias to the hidden layer output\n",
    "            h_out = np.concatenate((h_out, np.ones((1, 1))), axis=0)\n",
    "            # update the output layer\n",
    "            y = np.matmul(self.Who, h_out)\n",
    "            # apply the sigmoid activation function to the output layer\n",
    "            y = sigmoid_activation(y)\n",
    "            preds.append(y)\n",
    "\n",
    "        return y, hidden_states, preds\n",
    "    \n",
    "    # multi category cross entropy loss function\n",
    "    def loss_function(self, y, pred):\n",
    "        loss = np.sum(y * np.log(pred) + (1 - y) * np.log(1 - pred))\n",
    "        return -loss\n",
    "\n",
    "    # backpropagation\n",
    "    def backpropagation(self, batch_size):\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for i in range(0, self.trX.shape[0], batch_size):\n",
    "                x_batch = np.array_split(self.trX, batch_size)[i]\n",
    "                y_batch = np.array_split(self.trY, batch_size)[i]\n",
    "                \n",
    "                # initialize the gradients\n",
    "                dW1h = np.zeros_like(self.W1h)\n",
    "                dWhh = np.zeros_like(self.Whh)\n",
    "                dWho = np.zeros_like(self.Who)\n",
    "                \n",
    "                dH = np.zeros((self.N, 1)) # initialize the gradient of the hidden layer\n",
    "                \n",
    "                previous_state = np.zeros((self.N, 1)) # initialize the previous state as a zero vector (h_-1 = 0)\n",
    "                \n",
    "                for t in range(self.trX.shape[1]):\n",
    "                    ara = np.matmul(self.Whh, previous_state) + np.matmul(self.W1h, x_batch[t].T)\n",
    "                    previous_state = tanh_activation(ara)\n",
    "                    # add bias to previous state\n",
    "                    previous_state = np.concatenate((previous_state, np.ones((1, 150))), axis=0)\n",
    "                    ara = np.matmul(self.Who, previous_state)\n",
    "                    pred = sigmoid_activation(ara)\n",
    "                    d_o = ( pred - y_batch[t].reshape(-1, 1) ) * sigmoid_derivative(pred)\n",
    "                    dWho += np.matmul(d_o, previous_state.T)\n",
    "                    dH = np.matmul(self.Who.T, d_o)[:-1] * tanh_derivative(previous_state)[:-1]\n",
    "                    dWhh += np.matmul(dH, previous_state[:-1].T)\n",
    "                    dW1h += np.matmul(dH, x_batch[t].reshape(-1, 1).T)\n",
    "                    \n",
    "                    if t == self.trX.shape[1] - 1:\n",
    "                        correctPred = np.sum(np.argmax(pred, axis=0) == np.argmax(y_batch[t].reshape(-1, 1), axis=0))\n",
    "                \n",
    "                # update the weights and biases\n",
    "                self.Whh -= self.learning_rate * dWhh / trX.shape[1]\n",
    "                self.W1h -= self.learning_rate * dW1h / trX.shape[1]\n",
    "                self.Who -= self.learning_rate * dWho / trX.shape[1]\n",
    "                \n",
    "            accuracy = correctPred / trX.shape[0]\n",
    "            print(f\"Epoch: {epoch}, Accuracy: {accuracy}\")\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 150)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\NSagi\\Music\\Desktop\\2023-24_Fall\\EEE-443\\Mini-Project_2\\Human-Activity-Recognition-Classification\\deneme.ipynb Cell 8\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m rnn \u001b[39m=\u001b[39m RNN(trX, trY, tstX, tstY, N, learning_rate, mini_batch_size, num_epochs)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m rnn\u001b[39m.\u001b[39;49mbackpropagation(mini_batch_size)\n",
      "\u001b[1;32mc:\\Users\\NSagi\\Music\\Desktop\\2023-24_Fall\\EEE-443\\Mini-Project_2\\Human-Activity-Recognition-Classification\\deneme.ipynb Cell 8\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X12sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m dH \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmatmul(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mWho\u001b[39m.\u001b[39mT, d_o)[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m tanh_derivative(previous_state)[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X12sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m dWhh \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmatmul(dH, previous_state[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mT)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X12sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m dW1h \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmatmul(dH, x_batch[t]\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mT)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X12sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m \u001b[39mif\u001b[39;00m t \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrX\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#X12sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m     correctPred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39margmax(pred, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39margmax(y_batch[t]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 150)"
     ]
    }
   ],
   "source": [
    "# initialize the network\n",
    "N = 50\n",
    "learning_rate = 0.05\n",
    "mini_batch_size = 30\n",
    "num_epochs = 50\n",
    "rnn = RNN(trX, trY, tstX, tstY, N, learning_rate, mini_batch_size, num_epochs)\n",
    "rnn.backpropagation(mini_batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sddsd: [[ 0.02326866]\n",
      " [ 0.00384134]\n",
      " [-0.18629913]\n",
      " [ 0.05566894]\n",
      " [-0.1628338 ]\n",
      " [-0.09714913]\n",
      " [ 0.09012098]\n",
      " [ 0.04816209]\n",
      " [ 0.11316556]\n",
      " [ 0.1126785 ]\n",
      " [ 0.05520445]\n",
      " [-0.01201024]\n",
      " [ 0.02801943]\n",
      " [-0.02045145]\n",
      " [-0.03128348]\n",
      " [ 0.09867042]\n",
      " [ 0.02498328]\n",
      " [-0.24751347]\n",
      " [ 0.0124767 ]\n",
      " [ 0.00815191]\n",
      " [ 0.08548786]\n",
      " [-0.10555946]\n",
      " [-0.18262522]\n",
      " [-0.00644319]\n",
      " [-0.0428866 ]\n",
      " [ 0.0815097 ]\n",
      " [-0.2047452 ]\n",
      " [ 0.02128189]\n",
      " [ 0.07166018]\n",
      " [ 0.06903144]\n",
      " [ 0.02238825]\n",
      " [-0.09805824]\n",
      " [ 0.05349618]\n",
      " [ 0.04149045]\n",
      " [-0.07361007]\n",
      " [ 0.08843927]\n",
      " [-0.02802942]\n",
      " [-0.0581105 ]\n",
      " [-0.05802994]\n",
      " [ 0.01777098]\n",
      " [ 0.06871799]\n",
      " [-0.1156942 ]\n",
      " [ 0.00690742]\n",
      " [ 0.06683557]\n",
      " [ 0.05482055]\n",
      " [-0.00556718]\n",
      " [ 0.04620477]\n",
      " [ 0.07555757]\n",
      " [-0.01169871]\n",
      " [ 0.01891714]\n",
      " [ 1.        ]], shape: (51, 1)\n"
     ]
    }
   ],
   "source": [
    "sddsd = np.concatenate((hidden_states[149], np.ones((1, 1))), axis=0)\n",
    "print(f\"sddsd: {sddsd}, shape: {sddsd.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (50,4) and (150,1) not aligned: 4 (dim 1) != 150 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\NSagi\\Music\\Desktop\\2023-24_Fall\\EEE-443\\Mini-Project_2\\Human-Activity-Recognition-Classification\\deneme.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# loop over the training examples\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(trX\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m# forward pass\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     y_hat \u001b[39m=\u001b[39m rnn\u001b[39m.\u001b[39;49mforward_pass(trX[i, :, :])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m# backward pass\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     rnn\u001b[39m.\u001b[39mbackward_pass(trX[i, :, :], trY[i, :, :], y_hat)\n",
      "\u001b[1;32mc:\\Users\\NSagi\\Music\\Desktop\\2023-24_Fall\\EEE-443\\Mini-Project_2\\Human-Activity-Recognition-Classification\\deneme.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# loop over the time steps\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m# update the hidden layer\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     h \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mWhh, h) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW1h, x[:, t]\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39m# update the hidden layer output\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/NSagi/Music/Desktop/2023-24_Fall/EEE-443/Mini-Project_2/Human-Activity-Recognition-Classification/deneme.ipynb#W4sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     h_out \u001b[39m=\u001b[39m tanh_activation(h)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (50,4) and (150,1) not aligned: 4 (dim 1) != 150 (dim 0)"
     ]
    }
   ],
   "source": [
    "# implement the training loop and test the network on the test data\n",
    "# initialize the training loss\n",
    "tr_loss = np.zeros((num_epochs, 1))\n",
    "# initialize the test loss\n",
    "tst_loss = np.zeros((num_epochs, 1))\n",
    "\n",
    "# initialize the network\n",
    "N = 50\n",
    "learning_rate = 0.05\n",
    "mini_batch_size = 30\n",
    "num_epochs = 50\n",
    "rnn = RNN(trX, trY, tstX, tstY, N, learning_rate, mini_batch_size, num_epochs)\n",
    "\n",
    "# loop over the epochs\n",
    "for epoch in range(num_epochs):\n",
    "    # initialize the training loss for this epoch\n",
    "    tr_loss_epoch = 0\n",
    "    # initialize the test loss for this epoch\n",
    "    tst_loss_epoch = 0\n",
    "\n",
    "    # loop over the training examples\n",
    "    for i in range(trX.shape[0]):\n",
    "        # forward pass\n",
    "        y_hat = rnn.forward_pass(trX[i, :, :])\n",
    "        # backward pass\n",
    "        rnn.backward_pass(trX[i, :, :], trY[i, :, :], y_hat)\n",
    "        # update the weights and biases\n",
    "        Who = Who - learning_rate * rnn.delta_o * rnn.h.T\n",
    "        W1h = W1h - learning_rate * rnn.delta_h * rnn.h_out.T\n",
    "        Whh = Whh - learning_rate * rnn.delta_h * rnn.h.T\n",
    "\n",
    "        # calculate the training loss for this example\n",
    "        tr_loss_epoch = tr_loss_epoch + np.sum(np.square(trY[i, :, :] - y_hat))\n",
    "        # calculate the test loss for this example\n",
    "        tst_loss_epoch = tst_loss_epoch + np.sum(np.square(tstY[i, :, :] - y_hat))\n",
    "\n",
    "    # calculate the average training loss for this epoch\n",
    "    tr_loss[epoch] = tr_loss_epoch / trX.shape[0]\n",
    "    # calculate the average test loss for this epoch\n",
    "    tst_loss[epoch] = tst_loss_epoch / tstX.shape[0]\n",
    "\n",
    "    # print the training and test loss for this epoch\n",
    "    print(f\"Epoch: {epoch}, Training Loss: {tr_loss[epoch]}, Test Loss: {tst_loss[epoch]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "    def backward_pass(self, x, y, pred):\n",
    "        # initialize the error in the output layer\n",
    "        delta_o = np.zeros((6, 1))\n",
    "        # initialize the error in the hidden layer\n",
    "        delta_h = np.zeros((self.N, 1))\n",
    "\n",
    "        # loop over the time steps\n",
    "        for t in reversed(range(x.shape[1])):\n",
    "            # calculate the error in the output layer\n",
    "            delta_o = (pred[:, t].reshape(-1, 1) - y[:, t].reshape(-1, 1)) * pred[:, t].reshape(-1, 1) * (1 - pred[:, t].reshape(-1, 1))\n",
    "            # calculate the error in the hidden layer\n",
    "            delta_h = np.dot(self.Who.T) * delta_o + np.dot(self.Whh.T, delta_h)\n",
    "\n",
    "# Backpropagation Through Time (BPTT) function\n",
    "def bptt(trX, trY, W1h, Whh, Who, learning_rate, N):\n",
    "    hidden_states, outputs = forward_pass(trX, W1h, Whh, Who, N)\n",
    "    training_loss = cross_entropy_loss(outputs, trY)  # Compute training loss\n",
    "    dL_doutputs = outputs - trY\n",
    "\n",
    "    dW1h = np.zeros_like(W1h)\n",
    "    dWhh = np.zeros_like(Whh)\n",
    "    dWho = np.zeros_like(Who)\n",
    "\n",
    "    for t in reversed(range(trX.shape[1])):\n",
    "        dWho += np.dot(dL_doutputs.T, hidden_states)\n",
    "        dhidden = np.dot(dL_doutputs, Who) * dtanh(hidden_states)  # dtanh for derivative of tanh\n",
    "\n",
    "        for bptt_step in reversed(range(max(0, t - backprop_truncate), t+1)):\n",
    "            dWhh += np.dot(dhidden.T, hidden_states)\n",
    "            Xt_bias = np.hstack((trX[:, bptt_step, :], np.ones((trX.shape[0], 1))))\n",
    "            dW1h += np.dot(dhidden.T, Xt_bias)\n",
    "            dhidden = np.dot(dhidden, Whh) * dtanh(hidden_states)  # dtanh for derivative of tanh\n",
    "\n",
    "    W1h -= learning_rate * dW1h\n",
    "    Whh -= learning_rate * dWhh\n",
    "    Who -= learning_rate * dWho\n",
    "\n",
    "    return W1h, Whh, Who, training_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
